[
["index.html", "Nursing School Research Analytics and Computation Report Chapter 1 Motivations 1.1 Background 1.2 Executive Summary and Initial Recommendations: 1.3 The Interview Process", " Nursing School Research Analytics and Computation Report Steve Pittard 2019-03-26 Chapter 1 Motivations 1.1 Background The original scope of this report was focused primarily on problems associated with managing data and conducting omics-based research though it rapidly became apparent that there was as much concern about getting more support from Emory Core facilities. To a lesser extent (although still important) there is frustration with not being able to conveniently obtain data from the Clinical Data Warehouse and the perceived lack of customer focus exhibited by the Health/Research Services personnel. While data security is important, it must be balanced with the needs of the School and institution at large. **By all means, the institution should apply rigorous security to the data warehouse itself but this should not impair reasonable access paths to that information. This will likely require a rethinking of how protected data is offered though it should be done to better facilitate research pipelines. As research has been, (and continues to be), reliant upon computation, the need for software literacy and quantitative capabilities continues to grow. Core facilities are challenged to produce actionable results using current technologies such as Microbiome and Metabolomics though clients of these facilities want more in terms of explanation and follow up support as they refine results and arrive at publishable conclusions. This report attempts to capture some of the perceived gaps in institutional services and within the School of Nursing itself. Everyone agrees that change must be implemented relative to computation and analytics support to underwrite the ambitious research and publication aims of the School. 1.1.1 The “Omics” Problem The magnitude and highly dynamic nature of omics-based projects can lead to interesting explorations though ultimately the research should lead to publications in high impact journals and successful grant applications. These goals, however, can be frustrated by uncertainty about how best to manage data, which analytic techniques are most appropriate, where the computation should be performed, and how to effectively determine the biological relevance of the result. This can also be particularly challenging for doctoral students who can sometimes receive conflicting advice on how to structure omics-based thesis projects. Creating smooth workflows using omics-data is essential to progress and publications thus strategies must be developed to effectively deal with this situation. At a functional level, the development and implementation of a common logistical workflow would be helpful to guide faculty and doctoral students throughout the project life cycle. This is particularly true in the planning phase wherein documenting required personnel, appropriate percent effort, and anticipated service core involvement becomes essential to the outcome of having a defensible, publishable result that is accomplished according to known standards for a given Omics type (e.g. microbiome, metabolomics). 1.1.2 The Knowledge Gap - Communication With Cores Nursing School investigators engage Emory Core facilities to obtain services not commonly available or affordable within individual labs. The expectation is that these engagements will advance the quality and speed of research and that results emanating from these centers will be informative, accurate, and reflect a high level of consideration for individual project goals. However, a majority of those interviewed have concerns about the dynamics and products being returned from the Cores. (A notable exception is the Lipidomics facility which in the opinion of the interviewees has demonstrated an enthusiastic level of interest for user needs). The general concerns relate to up front project design, the interpetability of the results, as well as the overall level of attention given to the project. The impression is that many current omics-based projects wind up being unnecessarily reactive and delayed since investigators (and students) have ongoing questions after receiving results when, from the Core perspective, the engagement has concluded. The Core’s goal is to execute a discrete high-quality experiment thus an ongoing bioinformatics consultation might not be possible without additional financial support. Closing the gap between user expectations and the typical Core product is important as is having reasonable ongoing access to expertise (internal or otherwise). Addressing this gap involves a combination of activities involving the development of domain expertise by investigators (or their proxy) along with greater willingness by the Cores to treat engagements holistically as opposed to “one-and-done” transactions. 1.1.3 Data Access and Collaboration A fundamental problem exists in having convenient access to data as it makes its way through the analytics pipeline and in understanding what transformations have been applied (or not) to a candidate result. A solution such as RedCap is important though it can host only the more structured part of the project data whereas the associated omics data sets typically wind up on an Emory Box account that cannot be computed against. This leads to data being distributed to colleagues resulting in multiple copies that are transformed according to the needs of whomever is currently working on it (statistician, biologist, bioinformatician). Unfortunately, the transformed data and results (as well as the code used to produce it) are rarely reintegrated back into a repository for common reference. This is understandable as there is no common platform upon which to perform the work which could also serve as a sharing / collaboration environment. It is generally agreed that maintaining projects on laptops is a problem though it remains a popular approach. However, not all PIs feel comfortable sharing data especially in scenarios where the data has been difficult to obtain. It’s agreed that research reproducibility is important but there are sensitivities to having data commonly available during the project. (Appropriate security approaches can help here). Independently of these concerns, the funding agencies, (via concepts such as the “FAIR Guiding Principles” for data management and stewardship), are very much concerned with the “long-term care” of valuable digital assets, thus the appropriate annotation and archival of data is an obligation. 1.1.4 The Promise of Cloud Computing Computation remains a challenge in that the School does not currently “own” any significant computational resources which has led researchers to leverage personal and external professional relationships to accomplish work. This approach 1) does not scale well, 2) works against the idea of reproducible research, and 3) impairs collaborative ability. Cloud computing offers unprecedented access to scale-able, on-demand computation and storage resources in a manner that allows Emory researchers to be competitive with institutions that possess large, on-premise computational infrastructure. In effect, services such as Amazon and Google democratize computing by enabling access to anyone with a credit card and a willingness to learn how to leverage the environment. However, the path to productivity is not clear and there is confusion on how to approach Amazon services even before considering how to execute bioinformatics jobs and pipelines. The language of Amazon is one of enterprise services and architecture as opposed to research computing. The Emory LITS organization is in the process of rolling out a solution (ETA 2019) to help researchers but the presentations to date point to a model that involves a portal customized primarily for the benefit of LITS security interests. The larger question relates to what extent the cloud team will provide “in the trenches”, hands on training and help with selecting and managing various instance types, storage resources, and databases above and beyond the architectural level. This is where existing Cores could fill the gap or a more Nursing-centric approach could be helpful. 1.2 Executive Summary and Initial Recommendations: Note that these represent suggested starting points which can flexibly be implemented. Most, if not all, of these recommendations are based on (or are motivated by) suggestions from faculty who have attempted to address these problems in various ways including leveraging personal, professional, and external relationships. Further discussion is warranted particularly on items relating to the formation of a central resource (1.2.2) and the licensing of a data management and computation framework (1.2.1). The following statements were derived from the more detailed sections (2-6) of this document which in turn were based on the faculty interviews. 1.2.1 Data Management The School should consider use of a tool such as DNANexus or Seven Bridges Genomics. either of which would provide comprehensive support for managing sequencing-based projects, analytics, as well as the convenient addition of self-developed pipelines. Data management is a very important aspect of analysis and research although the current practices for supporting these activities are less than ideal. A framework is needed to maintain experimental data, code, and notebooks. There are currently three storage solutions (Isilon, Box, and Amazon) at Emory and it isn’t clear to researchers when and why to use them particularly when wanting to perform computation. Intermediate results and data transformations are not maintained alongside original data which impairs reproducibility. The data residing in Emory Box cannot be computed against and must be moved to individual computers (sometimes several) for downstream analysis. Emory should provide a comparable amount of free Amazon S3 storage to that which is available in Emory Box. S3 storage can be accessed by compute instances and would thus incentivize users to adopt Amazon cloud services. This would address a number of concerns of having “everything in one place” (to the extent that it is possible) along with computational results in a format that would enable reproducibility. Additionally, a solution such as DNANexus would facilitate the integration of genomic data with clinical and other phenotypic data in a secure and compliant environment. DNANexus is a cloud-based genome informatics and data management service that simplifies the organization of omics data as well as the development and execution of biomedical pipelines. While RedCap is useful for maintaining study information, being able to link in sequencing and sample information can be challenging and does not help for computation. For a more detailed analysis of this topic please consult section 4) Interaction with Cores. Note that the Winship Cancer Institute has recently decided to invest in DNANexus and the licensing model would allow for shared use that would enable detailed billing based on organization and department. 1.2.2 Nursing-Centric Analytics ‘Omics’ Resource The formation of a nursing-centric support group is recommended. Such a group would not replace or diminish the relationships with existing University Cores but rather improve the working dynamic since Nursing investigators would have an advocate acting on their behalf Availability of professionals who are well-versed in analytics, statistics, and Omics are critical to the research mission of the School. To this end, the formation of a nursing-centric support group is recommended. It would provide services for analytics, computing, and interactions with sequencing facilities (where desired) and generally exist for the benefit of investigators. This entity should be independent of the general Nursing IT group as the aims, workloads, and dynamics of each group are quite different. Whether this service center is an “official university core” or a formalized group is up for debate although the feedback on this topic is clear in that the group should prioritize Nursing School interests while also being available for salary support via external projects albeit secondarily. Duties would involve assistance with data management, cleaning, preliminary analysis, and ongoing participation in projects. Organizing training and providing orientation to the framework mentioned in item #1 would also be on the menu of services. It is important to note that such a resource could be referenced in applications for grants involving large scale processing. This would be evidence of a formal institutional commitment to Nursing analytics. Opinions vary as to the exact composition of this group and/or if it should draw from existing personnel (who aren’t already fully funded). Moreover, one investigator expressed concern about hosting such a group internally as resources might then be arbitrarily redirected to non-research projects or uniquely to projects associated with the most senior faculty. However, it was generally agreed that having more domain specific expertise specifically for the School of Nursing is definitely needed. In terms of implementing this resource, it is important to note that research computation presents a unique set of problems related to, though significantly different, from the production difficulties associated with Nursing Information Technology. Recruiting scientifically knowledgeable bioinformaticists is challenging enough without involving them in the resolution of basic IT issues that are better handled with more generic resources. To this end, the informatics resource should receive its own budget that focuses uniquely on the scientific and analytic interests of researchers. 1.2.3 Software Literacy And The Curriculum Improving general software literacy is essential as is being able to import/transform data, accomplish analytic tasks, create plots, query databases, and create digital assets. There is currently a gap in knowledge that should be addressed via a combination of formal courses and shorter, more focused types of education. The paper “Data integration in the era of omics: current and future challenges” discusses the idea that bioinformaticians are drawn from two distinct domains: 1) those who emerging from a computer science or mathematics background who have learned enough about biology to be helpful or 2) trained biologists who, of necessity, have acquired a knowledge of programming to approach their data. While this is an organic pattern that will likely continue it is generally agreed that a redevelopment of teaching practices that favor inter-disciplinary involvement is essential to produce computer savvy investigators. Many faculty pursue self-education but are interested in becoming much more self-sufficient with open source tools and the UNIX command line. This can be accomplished via participation in the Big Data course or more specific classes. A larger issue relates to what extent the Cores and LITS are interested in educating users, respectively, on domain specific pipelines and cloud computing ? Or, is it incumbent on the investigator to develop a team to ensure productivity ? Amazon presents a steep learning curve as can understanding results being returned from Cores. Some level of shared responsibility must be assumed in the development of final results. Part of the research process does involve self-education and a willingness to take a deep dive when attempting to adapt literature-based methods to local projects. Software literacy helps provide a common language and vocabulary for research. At this point, both students and faculty would benefit from courses that discuss and require the integration of computation, data, alongside with prototypical research challenges common to Nursing-based investigations. The path to such courses is relatively clear in terms of what is needed though there should be sufficient funding and lead time for development. The nature of these courses could be divided into two related areas: 1) Introductory material relating to the mechanics of UNIX command line, basic programming, data management, and cloud access 2) Applied courses that assume some level of software literacy. In terms of informal education one excellent (and cheap) resource is to arrange for an onsite Software Carpentry session which is a 1 to 3 day workshop devoted to teaching basic lab skills for research computing. These sessions are professionally taught and include hands on labs to learn the UNIX command line, R and Python Programming, Git, SQL and Databases. These are targeted to the novice but would also serve to reinforce skills. The material is open source and maintained on GitHub so we could possibly offer the course material with local teaching resources. The following graph illustrates the motivation levels for various software and command line topics after taking a Core level Software Carpentry class. 1.2.4 High Performance Computing The School should identify paths to cloud and command-line literacy via courses and training developed internally and in conjunction with Amazon Web Services. Research is increasingly reliant upon both desktop and high performance computation thus a commensurate level of support is needed. Computation remains a challenge in that the School does not currently “own” any significant computational resources which has led researchers to leverage personal and external professional relationships to accomplish work. This does not scale at all. Facility with cloud computing is a challenge even for those who are computationally aware thus for newcomers it is especially so. It is not currently clear to what extent LITS or existing Cores will help researchers address the skills gap or is it expected for investigators to self-educate and recruit students to handle computational aspects of their projects. Independently of from whom the help comes, the faculty were quite clear in their interest and desire for more assistance and training. If the School does NOT pursue a Nursing Centric resource then cloud education will be a function of informal resources and/or funded personnel specific to individual projects vis-a-vis a percent effort model. However, this does little to raise the general computational awareness at the School level. It would be useful for the LITS cloud team or Core facilities to offer ongoing orientation and support for adopting cloud resources along with expertise in system administration, package installation, database loading (both noSQL and SQL), programming (R, Python), and other services common to biomedical and bioinformatics projects. This includes agile and flexible support for opensource tools above and beyond standard enterprise tools. In absence of such help, the School of Nursing will have to develop internal resources which of course might even be preferable. In any case, the knowledge gap must be addressed. A secondary approach to the computation issue might involve partnering with the Department of Biomedical Informatics which maintains a sophisticated, well-functioning, well-supported computational cluster dedicated to aggressive research computing. This would have to be arranged but none of the projects currently being considered within the School of Nursing would represent a challenge to that environment. BMI would be an appropriate partner because research computing is “baked-in” to their mission and is thus seen as an essential service for researchers. I discussed a potential relationship with Jim Kinney (BMI System Lead) earlier this year but would need to renew those talks. 1.2.5 Research Desktop Support Nursing School resesrchers want a higher degree of “research aware” desktop support services from Nursing IT. While learning more about Amazon is important, all of the faculty interviewed have expressed disappointment with current School IT support which, as a group, does not seem motivated or interested in helping staff, students, or faculty particularly as it relates to research. Nursing School researchers need desktop assistance particularly as it relates to installing, updating, and running opensource packages such as R, Python, Anaconda and associated opensource tools. The School faculty should not expect IT personnel to actively conduct research or understand the intricacies of software workflows. However, the IT group should be able to troubleshoot package installation conflicts, prerequisites, and perform upgrades necessary to enable base level research exploration. In general most faculty believe that Nursing IT should be incentivized to more aggressively support research including a basic level of cloud orientation. The fact that the IT group is currently not oriented towards such activities should be not an ongoing rationale to keep the status quo. Lastly, it is clear that Nursing IT has unique challenges that for the most part warrant separate consideration from research computation. That is, it is not advisable to create a merged or combined group under the IT flag since research computation has both technical and personnel needs that require guidance by scientifically oriented leadership. While it might be tempting to generically group everything relating to technical needs under one group such an action would short-change the interests of both groups. The recruitment of highly-skilled analytics and computational personnel is a challenge deserving of a standalone organizational structure. 1.2.6 Alternatives to Local Core Processing The School should develop relationships with trusted external scientific resource providers to process urgent requests for sample processing and analysis consultation. This should also include training resources which could be accomplished virtually, on-premise (for larger groups), or remotely. Even if all concerns with local Cores are fully addressed there remains a need for expedited processing and domain specific expertise to address backlogged projects or efforts requiring special care during processing. Not every project will require this but there should be a reliable outlet for “blocked” projects or those requiring a rapid turnaround. In particular, we should organize training to learn “best practices” in the processing and analysis of Microbiome and Metabolomics. At least one faculty member has used an external lab for Microbiome and another is contemplating the re-sequencing of a large number of samples via the Ravel Lab at the Institute of Genome Sciences to obtain domain expertise starting at the sequencing level. 1.2.7 Student Recruitment Deliberate efforts should be made to recruit graduate students with ability and/or interest in data manipulation and analysis since the nature of research within the school will require such a background. It is difficult to imagine a scenario wherein a graduate student could be successful without acquiring at least a basic fluency with these tools. Obviously, such skill can be developed over time though biomedical research assumes that students can clean, reshape, and transform data both prior to analysis and afterwards. While no one believes that using only student “labor” to accomplish projects is reasonable, there is a goal of having software literate students who can “dive in” to projects. However, the School Dean did express a specific concern that it can be challenging for doctoral students who sometimes receive conflicting advice on how to structure omics-based thesis projects. So while having software savvy students is a plus, they will still require guidance in the selection and execution of their thesis work which in turn assumes the existence of a knowledgeable supportive community. For better or worse, the domain of biomedical, bioinformatics, and nursing research requires a base level of quantitative skill and facility with software packages such as R, Python, and various open source tools. 1.2.8 Improved Project Logistics Faculty want access to personnel familiar with the statistics, computation, and bioinformatics as part of the research planning phase. This could be part of the previously mentioned Nursing Omics Resource or independent of it. Researchers would like more detailed upfront estimates of statistics, analytics, and computation costs to better project cost of staff involvement. Not knowing how much (in time, money, and personnel) the key aspects of a project will “really” involve is a concern. This could be implemented separately of the proposed local Nursing Omics resource though if such a resource did exist then this person could also be part of that that. The overall idea is to have accurate and reliable estimates of sequencing, analytics, and computation work. Some junior faculty feel that they cannot fully access personnel due to lack of funding or because the more experienced personnel are already mostly engaged on other projects. In general, having a standard logistical workflow that specifies who to involve, when, and to what extent is needed. This includes collaborating domain expertise (statistics and bioinformatics personnel) as well as key Core facilities - internal or external to Emory. 1.3 The Interview Process Conducting these interviews was a smooth process as those contacted were very forthcoming with helpful responses that were very consistent across the topic areas described in this report. Deviations of opinions did sometimes occur along the lines of junior and senior faculty although all of the senior faculty with whom I spoke were keenly aware of the difficulties facing junior faculty and appeared to be sympathetic. Everyone was collegial and supplied viewpoints that will benefit the School as a whole. The concerns expressed were entirely relevant to improving research processes and it’s clear that even though there are some challenges, people are nonetheless working very hard to get things done. The School of Nursing has definite strengths in its clinical programs combined with accomplished and talented faculty. It remains a priority to continue to apply for data-based grants and to this end the School must be able to point to official and strong support for analytics and computation within proposals to be competitive. The participants in the interview process were: Linda McCauley, Anne Dunlop, Carolyn Clevenger, Jessica Wells, Irene Yang, Rebecca Mitchell, Jinbing Bai, Erin Ferratti, Betsy Corwin, Nicole Carslon, Despina Tsementzi, Anna Knight, Deborah Bruner, Mary Gullate, Melinda Higgins, and Jason Atkins. I also had a discussion with Karl Moran at Microbiome Insights since they performed work for Irene Yang. I also contacted Ethenia Why at the Biostatistics Core at Hopkins for comments on their role in Microbiome analysis. I’ve also got an inquiry to Steven Gill at the University of Rochester Microbiome Core. I’ve had conversations with Madhusmita Behera who is the Director of Informatics at Winship Cancer Institute which is also working towards a usable solution for Data Management and Computation. The following sections (2-6) represent the interview summary information which was used as a basis for the above recommendations. Each section takes a deeper dive into the area under consideration. "],
["data-management-1.html", "Chapter 2 Data Management 2.1 Data Hosting 2.2 Source Code Maintenance 2.3 Notebooks and Reproducible Research", " Chapter 2 Data Management Summary: The organization, preservation, and sharing of data are very important aspects of analysis and research although the current methods for doing this are not satisfactory. Intermediate results and data transformations are not maintained alongside original data which impairs reproducibility. A framework(s) is needed to maintain experimental data, code, and notebooks. 2.1 Data Hosting The primary method of managing data involves the use of Emory Box (https://emory.account.box.com/login in conjunction with RedCap https://www.project-redcap.org/ although no one interviewed believes Box to be ideal or particularly desirable outside of its approved use for hosting health data. The data being hosted on Box is typically distributed to collaborators and analysts who in turn maintain personally transformed versions of the data and associated intermediate results. It is rare that those results and transformed datasets are re-integrated back alongside the original data in a manner that facilitates reproducibility. While study data is being maintained in RedCap there are an increasing number of associated experimental data types that aren’t appropriate for tracking in RedCap thus they need to be maintained separately on Box. However, the Box resource cannot be computed against. Some faculty do use R Notebooks for reproducibility but point to the problem of keeping track of results generated by others who might “touch”&quot; the project and preserve their own scripts and transformed data on their laptop. Given that shuffling data around is largely a manual process, trying to “work back” from results to the original data is challenging. 2.2 Source Code Maintenance Many of the reference software pipelines for Microbiome analysis (as well as other data types) are obtained from literature references, training, and/or vignettes that might be supplied with a given software package. It is expected that changes will be made to scripts simply to accommodate local data sources which might very well lead to questions and interactions with package authors, statisticians, and more generally anyone who might be able to help the research bypass roadblocks. Thus, the state of a script or code can vary greatly at any time depending on where in the process things are. These scripts are almost always maintained on personal laptops or desktop computers although at least one person uses Git and GitHub to archive scripts. Even so, the scripts are typically highly customized for a specific project. Also, GitHub is for maintaining code changes and not data thus it is inappropriate to host data and results (intermediate or final) along with the code. It’s also true that GitHub exists to encourage collaboration and co-development though not everyone who would use Git or GitHub feels that the code is in a “good enough” state to push to a repository for general use and inspection. 2.3 Notebooks and Reproducible Research Some faculty are using R Notebooks to capture a narrative alongside the code used to generate results. These notebooks are prime candidates for registration on GitHub as it allows others to benefit from the work and permits easy retrieval of previous versions. Of course, some do not wish to share their code for various reasons such as that is in development. Another reason is that the end result is simply a minor variation of a published pipeline (e.g. Qiime2 or dada2) in response to specific sequencing problems or situations that might not relate to another PIs project. Some labs have in fact maintained scripts in GitHub or on the Costas website at http://enve-omics.ce.gatech.edu/ although the practice is not prevalent. Reproducing research is major concern that has been placed aside in favor of simply being able to get analysis accomplished (which itself has been a challenge). In short “the data can’t grow roots anywhere” so being able to integrate all intermediate results, let alone track the provenance and chain of custody thereof, has been very challenging outside of the simplest of projects. A larger issue exists in knowing the “best practices” associated with creating reproducible resources. Some faculty do know about “notebooks” in R and Python and see the value in using them although integrating a personal notebook with that of an analyst or collaborator remains a challenge. Keeping copies of “cleaning” scripts in addition to analysis pipelines is a priority though concern remains at being able to reproduce results if and when key personnel leave the department. "],
["software-literacy.html", "Chapter 3 Software Literacy 3.1 Concerns About Falling Behind 3.2 Workshops 3.3 SAS/SPSS vs Open Source Tools 3.4 Attracting Software Literate Students", " Chapter 3 Software Literacy Summary: Having software literacy is essential to research success. Being able to import/transform data, accomplish analytic tasks, create plots, query databases, and create digital assets will facilitate publication and grant submissions. Many faculty would like to become more self-sufficient. 3.1 Concerns About Falling Behind Some faculty have improved their knowledge via self-education or participating in the Big Data class though most want more experience and are frustrated with not being able to fully comprehend the code in published pipelines and/or how one might modify or extend the code to pursue ad-hoc analysis paths. Consequently, they feel “locked in” and limited by their relative lack of the UNIX command line and general programming knowledge and might not then feel confident enough to modify code for fear of “breaking” something. This is especially concerning given that the junior faculty know that they need solid preliminary data before they can apply for an R series grant. At this point being able to conduct and understand analytics results is a barrier to progress. 3.2 Workshops A popular approach to learning coding in addition to analysis are domain specific workshops such as those offered for Qiime, dada2, and the 5-day training at UAB which has apparently now been reduced to a half day. However, there is wide variation reported in the quality and applicability of general workshops with some being somewhat helpful but not necessarily representative of “real world” data. This was a common complaint especially relative to Microbiome projects wherein the sequencing data coming back from the sequencing center was causing problems with the standard published dada2 pipeline. The UAB workshop was singled out as being particularly helpful since it began with sequencing considerations all the way to full on analysis and result reporting. It has been suggested that 1) The School identify quality training resources and 2) create relationships with them to arrange for on-site or remote training. The Microbiome Insights group Lab (microbiomeinsights.com) will offer onsite or virtual training sessions on demand for individuals or groups although more work needs to be done to identify specific topics of interest. 3.3 SAS/SPSS vs Open Source Tools Some faculty have graduate training and exposure to SAS and SPSS and remain attracted to the integrated nature of those tools but realize that R and Python are the more relevant frameworks for the Omics work at hand. To this end, Coursera and Edx courses have been useful to pick up targeted knowledge though it is generally agreed that project driven coding is the best for learning and reinforcing skills. Leveraging Software Carpentry https://software-carpentry.org/lessons style courses is also a reasonable possibility since they offer 1 to 3 days workshops desgined to impart basic computation skills for researchers. One faculty member suggested making the Big Data class a two-semester sequence with one class being devoted to the key aspects of the language which, in combination with the project-based course, would represent a powerful educational offering. However, some faculty might not wish to devote that much time to this effort though willingly concede that it would be helpful. 3.4 Attracting Software Literate Students There is an associated interest in attracting students who possess programming skills or are at the very least enthusiastic about a learning path that involves programming. This is both to facilitate research and to make the student experience more productive since analysis of experimental data types is likely to be a major theme in most thesis projects. It is important to note that such students are not being seen as a substitute for more formal types of support though as part of their educational experience they could work in an internal service center or core to interact with experienced professionals. Again, this is not intended to be a roundabout method of getting research projects accomplished but an attempt at accelerating student knowledge of “real world” analysis applications. "],
["interaction-with-cores.html", "Chapter 4 Interaction with Cores 4.1 Expectations of Cores 4.2 Understanding Results 4.3 Need for More Consultation 4.4 Possible Solutions", " Chapter 4 Interaction with Cores Summary: Satisfaction levels with Emory Cores could be better. Researchers want more up front support in addition to back end consultation. Faculty also understand that they have a responsibility to acquire the requisite knowledge to speak intelligently about the project but until they “get there” they will need help. 4.1 Expectations of Cores Expectations vary as to what Emory Cores should be providing customers with some faculty wanting significantly more up front and post-result assistance on how to accomplish variations in analysis. Communication difficulties with the Sequencing Core were mentioned by a majority of those interviewed with the conclusion that perhaps seeking an external partner with expertise in Microbiome and Metabolomics would be something to consider. One faculty member has used the services of an external provider mostly for analytics and was happy with the result though follow-up dialogue was required to clarify conclusions. Another faculty member retained a postdoc to actually do the sequencing and analysis which resulted in a lean, efficient project since it was all done under the supervision and involvement of one person. It was acknowledged that this situation is rare and probably not something that could be reproduced and scaled for use by others within the School It’s also a function of availability of qualified postdocs who have enough expertise in each component area. There is also a general interest in having additional supporting documentation on how the samples were processed along with any and all details relating to quality control. The following figure shows a typical work flow based on a gut microbiome sample. The customary approach has been to accomplish Steps 2-3 (sometimes 1 also) via a trusted service core facility with steps 1, 4 and 5 being performed locally within the school by faculty, students, professional staff, collaborators and/or a combination thereof. Some faculty have leveraged personal relationships and employed external labs to accomplish all steps simply to expedite project completion although being able to conduct the analysis locally and within a reasonable time frame is a goal. Figure 4.1: Typical Microbiome Workflow If the analysis steps are broken down into the component tools (e.g. Qiime, DADA2, Mothur, etc) there is wide variation in software knowledge on how to best implement the software to arrive at a biologically relevant result. Additional experimentation with various software tools and pipelines workflow will occur although some tools require more substantial computation environments such as the Amazon cloud which itself can present a steep learning curve for investigators. After receiving initial results from the Core, investigators will frequently reengage with followup questions to better understand the result. Not all Cores have the resident domain expertise (or interest) to sustain and ongoing followup dialogue or, if they do, staff might not currently be available. 4.2 Understanding Results The following figure captures the essence of the challenges when interacting with Core facilities. The best situation occurs when there is an intersection of knowledge between the facility and the investigator to the point wherein questions and concerns are easily addressed. Both sides have a sufficient background to ask pointed questions about software pipelines used in the process as well as some knowledge of the domain from which the data was generated (e.g. Microbiome, Metabolomics, Lipidomics). The second case represents the case wherein the investigator has some knowledge of at least one of the areas but needs significantly more help in other areas. This situation is more common than the first. There is light intersection of shared knowledge which subsequently provokes more questions (sometimes more advanced, sometimes basic and remedial). 4.3 Need for More Consultation Additional consultation from the Cores is required given that researchers might not be well trained in a specific technique or field. This is true for both study and experimental design as well as result interpretation. Additionally, being able to point to vital working relationships to local Cores is very helpful when applying for grants. In absence of that type of relationship then external providers must be considered. One problem with core facilities is the recruitment and retention of the necessary domain expertise to complete a number of projects on time. Typically, core facilities are staffed with junior level faculty who are on their way to other career opportunities or staff who are working (many times temporarily) for less than market salaries perhaps because a partner or spouse is employed elsewhere within the institution. Lack of advancement and funding for professional development can dissuade otherwise qualified personnel from pursuing such positions. Universities such as Vanderbilt have begun to establish job descriptions and promotion and tenure policies relevant to the issue of career tracks for core directors and personnel. 4.4 Possible Solutions In response to faculty input the following figure represents a type of interaction with internal cores that can help. It assumes that supplemental expertise can be assigned or mobilized in parallel (to the extent that can currently be achieved) to fully leverage results coming back from a Core. Some investigators might already have this relationship in some form (e.g. postdocs, junior faculty working on the project) but it’s not a common scenario nor is it one that is realistic for junior faculty. The following figure represents a distillation of input from faculty wherein there is ready access to a group of integrated professionals who can manage interactions (where requested) and fulfill some of the needs that is typically pushed back onto the investigator. In this scenario investigators still retain the ability to go directly to a Core or leverage the strengths of the internal Core who can manage relationships, organize training, and intelligently allocate personnel for various tasks. Obviously, this will involve recruitment and possible reorganization of existing resources (those who aren’t already fully funded). "],
["project-initiation-dynamics.html", "Chapter 5 Project Initiation Dynamics 5.1 Continuity Throughout the Research Process 5.2 Estimating Effort 5.3 Grants", " Chapter 5 Project Initiation Dynamics Summary: People are generally happy with the project initiation process (PIF) as it alerts the organization to an impending proposal. Junior faculty appreciate the assistance and perspective being offered by senior researchers in this process and would like to see this continue. Where things aren’t so good relate to the availability of statistics, analytics, and computation resources. If one does not have funding, then this becomes a problem. Others feel that the more experienced technical personnel are not available because their time has been “bought out” by more senior personnel. 5.1 Continuity Throughout the Research Process Having access to analytics, statistics, computation, and biological expertise is important though being able to have simultaneous access to each of these professionals (assuming they are separate individuals) would be useful since no on individual has the “whole picture” and must frequently defer to another before being able to proceed past a roadblock. Initial consultations tend to center around design and general impressions about how to proceed though once the work starts, questions naturally emerge in response to intermediate results that might require input from a number of people. This is particularly true when investigators are leveraging their network and/or past professional relationships in other departments or institutions. They do this because of lack of funding to adequately compensate existing staff unless of course funding can be found within K grants. 5.2 Estimating Effort Investigators trust that self-declared experts and collaborators are providing reasonable effort estimates and, more importantly, that they will provide analysis support (or someone from their lab will) although this hasn’t always panned out in a way that was expected. Consequently, effort has been obtained from whatever available sources possible. The PIF approach does help to initiate the research process and alerts the organization to an impending grant application. The advice one receives as well is generally good though the staff in place for Omics support may not be available for the project or have the current skills to address the issues. 5.3 Grants Career Development Awards (K grants) are plentiful and many junior faculty feel that there is adequate support and mentorship on how to write proposals at least at that level. The perceived problem is that of generating the necessary preliminary data for obtaining an R series grant. Faculty point to difficulties in getting good results from the recent various Microbiome and Metabolomics projects. There is also a concern that pursuing grants of larger scope will be challenging given that the it is difficult to realistically reference formal means of analytics and computation support within proposals. "],
["computation.html", "Chapter 6 Computation 6.1 Data Management and Computation 6.2 Cloud vs Local Resources 6.3 Desktop Support for Open Source Analysis Tools 6.4 General IT Support 6.5 Databases and Applications", " Chapter 6 Computation Summary: Computation underlies research analytics though no official resource exists within the school, which can be challenging. Faculty use whatever resources they can find and will leverage relationships (personal and professional) to work around the issue. Lots of code and data winds up on laptops which works against reproducibility, security, and project continuity. Computation is not something that was directly mentioned by most faculty simply because it is generally considered to be an underlying component to data management and analysis and is therefore generally not the first topic referenced when discussing challenges. However, everyone understands that analysis and data manipulation must occur “somewhere” which is why some faculty leverage personal and professional relationships (Math/CS, Georgia Tech, Winship Cancer Institute) to accomplish the computation. Unfortunately, these resources aren’t necessarily available to other School of Nursing Faculty or if they are now, might not be if the SON person were to leave. 6.1 Data Management and Computation Smaller projects can in fact be accomplished using laptops and desktops though the trend has rapidly moved towards more samples per project thus being able to easily and conveniently compute against data sources is very important. This is a major limitation of Emory Box in that the data cannot be directly accessed via software. It might be more convenient for it to be in Amazon S3 bucket or a folder attached to a compute node, or in a system such as DNANexus or Seven Bridges both of which are enterprise frameworks for data management, analysis, and computation. These are currently being considered by WCI in support of their ORIEN http://oriencancer.org/#about project though it is quite possible that the School of Nursing could benefit from using the license also since it would provide a standard tool for management, analysis, and compute. However, embracing these tools would still involve formal training and orientation to ensure productivity. 6.2 Cloud vs Local Resources All of those interviewed are aware of the importance of resources such as Amazon or Google but lack the training to reasonably approach these resources directly unless “chaperoned” by someone more knowledgeable or by involving a funded collaborator. A minority of those interviewed express an interest in knowing how to configure cloud resources at a “nuts and bolts” level though most do not see immediate value in that. Although they do understand that being more facile at the UNIX command line and with R and Python can only help them. In the end, faculty are not fixated on a specific architecture or method of computation as long as it is readily available and accessible using standard, documented methods. Many faculty are getting their computational work done “by hook or by crook” so they are open to something more generally accessible that is setup according to a standard and doesn’t require them to “jump around” to different resources throughout the course of the project. 6.2.1 Onboarding Cloud Support On boarding to the Cloud is a problem. The cloud’s ability to match the scope of most any research project is indeed a true convenience which, however, requires significant knowledge to fully exploit. Knowing how to responsibly provision storage, “spin up” instances, create databases, and effectively close out projects are important skills. It has been difficult getting a clear message from the institution as to when a service offering would be official and what precisely the support mechanism would provide particularly as it relates to hands on support and assistance with managing cloud-based instances. A soft opening was announced for Fall of 2018 though the service arrival date is now “early 2019”. Investigators will need assistance and/or proxies to handle the foundational work which would typically involve students although a more official, permanent, and reliable form of support is essential since students and postdocs eventually move on. In absence of enthusiastic end-user support it will likely not be heavily used except by those already knowledgeable and/or funded specifically to the do the work. Some reference the TARDIS cluster as being representative of a computational resource that was poorly supported from the user point of view. Questions went unanswered nor was there lcoal Emory support except in the form of project or product managers who did not offer actual support of assistance. Investigators were expected to “self-educate”. The hope is that this approach does not persist relative to the Amazon offering. 6.2.2 Post Project Data Archival Research evolves over time and involves input from collaborators (statisticians, analysts, bioinformatics etc.) which means that the data must remain resident on the cloud as the project evolves. This ongoing occupancy involves costs and while someone could move the data off to cheaper storage and then move it back to EBS, this is inconvenient and also interrupts the continuity. Local resources are catch as catch can (frequently by personal arrangements) but charges don’t accrue although if the person leaves then access to the data and resource, along with a description thereof go missing. Being able to maintain data on the Amazon cloud is an interest especially with the attractive life cycle management tools that can push out data to Glacier for long term, inexpensive archical. Addiitonally, Amazon provides versioning, flexible permission schemes, and tiers for infrequently accessed data though intelligent use of these features will require support from the institution. It is not apparent that LITS is willing to offer this especially given that the perferred storage platform is the Isilon storage system which has no Glacier-like capability. Putting data in Box is “okay” but 1) it cannot be computed against and 2) if the institution is truly moving towards a cloud-first solution then investigators should be allocated Amazon S3 storage equivalent in size to the free Emory Box offering. 6.3 Desktop Support for Open Source Analysis Tools Faculty have expressed concern at the level of IT desktop support they receive which is limited when considering that they need to conduct analyses on their desktops using open source tools. Put simply, Nursing School IT does not appear to be incentivized to help researchers. Being able to install and update opensource tools (e.g. R, Python, add-on packages) AND receive troubleshooting assistance is a common need although it has been quite difficult to obtain such help. While faculty would gladly use a more fully configured computational resource specifically customized for analysis and data manipulation there will always be a need for desktop computation simply to try things out and/or do trial runs of pipelines found in literature. To this end having someone in IT who is motivated to do this would be helpful. Note that faculty are NOT expecting the IT group to provide research advice or debug programming issues. However, they should be able to troubleshoot basic installation problems and be able to assist in the updating of packages and generally be aware of desktop issues as it relates to research. 6.4 General IT Support The focus of the interview process was primarily to collect impressions about the research process with a general focus on data management, analytics, and related issues. However, it wasn’t surprising that “side” discussions about IT emerged as many of the faculty weren’t/aren’t entirely clear on the role that group plays in research matters if any. Generally, expectations have been, and continue to be, low about what IT can do to facilitate research though it was also agreed that this should not necessarily be acceptable - especially if Nursing IT receives budget to assist faculty beyond merely reproducing LITS type services locally. Simply because the group has not been motivated in the past to help researchers should not then mean that the group should not be reconfigured around priorities of benefit to investigators. This could be useful in the sense that a reconfigured group could maintain local servers and databases but, again, this assumes a commitment to a new direction that would most likely require new (or retrained) personnel. Training on Amazon in particular should be a priority for IT. 6.5 Databases and Applications Some faculty would want to do this in support of a research project though by far the more pressing need relates to analytics, statistics, and omics. Deploying web-enabled apps and database is actually a very common interest in research departments across the institution. Unfortunately, there is no common Emory service for this which then means that apps must be locally developed and maintained on local servers. Obviously, Amazon could be used as a foundation for apps, but ongoing cost is a concern. Still, investigators would pay if the resource were well supported, backed up, and maintained. In absence of this, the School would have to provide server space (backups, patches, upgrades, security auditing) as well as DBA (Database Administration) support for app hosting which in turn would require administrators. These administrators would NOT necessarily have to have research or analytics skills so if the IT group were reconfigured to provide more services then this might be one of them. "]
]
